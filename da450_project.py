# -*- coding: utf-8 -*-
"""DA450 Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UzY65RSFN6_2TiOyQxqkN8sYfohm7fRE

## Lodaing Dataset
"""

#https://www.kaggle.com/datasets/muhammadalbrham/rgb-arabic-alphabets-sign-language-dataset

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d muhammadalbrham/rgb-arabic-alphabets-sign-language-dataset

!unzip rgb-arabic-alphabets-sign-language-dataset.zip -d /content/arabic_sign_language

import os

data_path = '/content/arabic_sign_language'
print(os.listdir(data_path))

"""## Importing Libraries"""

import os
import matplotlib.pyplot as plt
import cv2
import numpy as np
from PIL import Image, ImageFile
import random
from collections import Counter
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import shutil
from tqdm import tqdm
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.utils import to_categorical

"""## Data Visulization and Exploration"""

data_path = '/content/arabic_sign_language/RGB ArSL dataset'
classes = os.listdir(data_path)
print("Number of classes:", len(classes))
print("Class names:", classes)

def count_total_images(base_path):
    total_images = 0
    # Loop through each label folder
    for label in os.listdir(base_path):
        label_folder_path = os.path.join(base_path, label)

        # Loop through each image file in the label folder
        for img_name in os.listdir(label_folder_path):
            img_path = os.path.join(label_folder_path, img_name)

            # Check if the item is an image (optional check based on file extension)
            if img_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):
                total_images += 1

    print(f"Total number of images: {total_images}")
    return total_images

# Call the function to count total images
count_total_images(data_path)

def show_images_per_class(base_path, classes, images_per_class=5):
    plt.figure(figsize=(15, len(classes)*2))
    i = 1
    for label in classes:
        folder_path = os.path.join(base_path, label)
        images = os.listdir(folder_path)[:images_per_class]
        for img_name in images:
            img_path = os.path.join(folder_path, img_name)
            img = Image.open(img_path)
            plt.subplot(len(classes), images_per_class, i)
            plt.imshow(img)
            plt.axis('off')
            plt.title(label)
            i += 1
    plt.tight_layout()
    plt.show()

# Call the function
show_images_per_class(data_path, classes, images_per_class=3)

image_sizes = []
image_formats = []

for label in classes:
    folder_path = os.path.join(data_path, label)
    for img_name in os.listdir(folder_path):
        img_path = os.path.join(folder_path, img_name)
        try:
            with Image.open(img_path) as img:
                image_sizes.append(img.size)
                image_formats.append(img.format)
        except:
            continue

print("Most common image sizes:", Counter(image_sizes).most_common(5))
print("Image formats:", Counter(image_formats))

#  Histogram of image widths and heights
widths = [size[0] for size in image_sizes]
heights = [size[1] for size in image_sizes]

plt.figure(figsize=(12, 5))

# Histogram of widths
plt.subplot(1, 2, 1)
plt.hist(widths, bins=20, color='lightcoral', edgecolor='black')
plt.title('Distribution of Image Widths')
plt.xlabel('Width (pixels)')
plt.ylabel('Number of Images')

# Histogram of heights
plt.subplot(1, 2, 2)
plt.hist(heights, bins=20, color='mediumseagreen', edgecolor='black')
plt.title('Distribution of Image Heights')
plt.xlabel('Height (pixels)')
plt.ylabel('Number of Images')

plt.tight_layout()
plt.show()

# Count the number of images per class
images_per_class = {}
for label in classes:
    folder_path = os.path.join(data_path, label)
    images_per_class[label] = len(os.listdir(folder_path))
print("\n Number of images per class:")
for k, v in images_per_class.items():
    print(f"{k}: {v} images")

#  Bar chart: Number of images per class
plt.figure(figsize=(12, 6))
plt.bar(images_per_class.keys(), images_per_class.values(), color='skyblue')
plt.title('Number of Images per Class')
plt.xticks(rotation=45)
plt.ylabel('Image Count')
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

target_size = (224,224)

def show_resized_sample_images(base_path, classes, samples=5):
    plt.figure(figsize=(10, 5))
    for i in range(samples):
        label = random.choice(classes)
        folder_path = os.path.join(base_path, label)
        image_name = random.choice(os.listdir(folder_path))
        image_path = os.path.join(folder_path, image_name)

        img = Image.open(image_path).convert('RGB')  # Ensure it's RGB
        img_resized = img.resize(target_size)

        plt.subplot(1, samples, i+1)
        plt.imshow(img_resized)
        plt.title(label)
        plt.axis('off')
    plt.tight_layout()
    plt.show()

show_resized_sample_images(data_path, classes)

"""## Preprocessing

1. Loading the Images
2. Resizing the Images
3. Normalization
4. Encoding Labels
5. Data Splitting
6. Data Augmentation
"""

# Allow loading truncated images
ImageFile.LOAD_TRUNCATED_IMAGES = True

import os
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
import numpy as np

data = []
labels = []
categories = os.listdir(data_path)  # List of category names

target_size = (224, 224)    # Resize target

# Loop through all categories and images
for category in categories:
    category_path = os.path.join(data_path, category)

    for img_name in os.listdir(category_path):
        img_path = os.path.join(category_path, img_name)

        try:
            # Load and resize the image
            img = load_img(img_path, target_size=target_size)
            img_array = img_to_array(img)
            data.append(img_array)
            labels.append(category)

        except Exception as e:
            print(f"Skipped corrupted image: {img_path} | Reason: {e}")

# Encode labels to numbers, then one-hot encode them
label_encoder = LabelEncoder()
encoded_labels = label_encoder.fit_transform(labels)
categorical_labels = to_categorical(encoded_labels)

# Final shape info
print(f" Loaded {len(data)} images.")
print(f" Data shape: {np.array(data).shape}")
print(f" Labels shape: {categorical_labels.shape}")

import matplotlib.pyplot as plt
import numpy as np

def show_sample_images(data, labels, label_encoder, samples=10):
    plt.figure(figsize=(15, 4))
    indices = np.random.choice(len(data), samples, replace=False)  # Random indices

    for i, idx in enumerate(indices):
        img = data[idx]
        label = label_encoder.inverse_transform([np.argmax(labels[idx])])[0]  # Convert back to label name

        plt.subplot(1, samples, i + 1)
        plt.imshow(img / 255.0)  # Normalize image for display only
        plt.title(label)
        plt.axis('off')

    plt.tight_layout()
    plt.show()

# Call the function
show_sample_images(data, categorical_labels, label_encoder, samples=10)

"""Spliting dataset"""

X_train, X_test, y_train, y_test = train_test_split(data, categorical_labels, test_size=0.2, random_state=42)
X_test,X_val,y_test,y_val=train_test_split(X_test,y_test,test_size=0.5, random_state=42)
X_train = np.array(X_train)
X_val = np.array(X_val)
X_test = np.array(X_test)
y_train = np.array(y_train)
y_val = np.array(y_val)
y_test = np.array(y_test)
print(f'X_train shape is {X_train.shape}')
print(f'X_val shape is {X_val.shape}')
print(f'X_test shape is {X_test.shape}')
print(f'y_train shape is {y_train.shape}')
print(f'y_val shape is {y_val.shape}')
print(f'y_test shape is {y_test.shape}')

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Create ImageDataGenerator with augmentation and normalization for training
train_datagen = ImageDataGenerator(
    rescale=1./255,              # Normalize pixel values from [0, 255] to [0, 1]
    rotation_range=30,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    brightness_range=[0.8, 1.2],
    horizontal_flip=True,
    vertical_flip=False
)

# For validation and test: only normalization (no augmentation)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Create generators
train_generator = train_datagen.flow(X_train, y_train, batch_size=32)
val_generator = val_datagen.flow(X_val, y_val, batch_size=32)
test_generator = test_datagen.flow(X_test, y_test, batch_size=32)

print("Number of training images:", len(X_train))
print("Number of validation images:", len(X_val))
print("Number of test images:", len(X_test))

import matplotlib.pyplot as plt
import numpy as np

# Take one batch from the generator (batch size = 16)
images, labels = next(train_generator)

# Plot the first 8 augmented images
plt.figure(figsize=(12, 6))
for i in range(8):
    plt.subplot(2, 4, i + 1)
    plt.imshow(images[i])
    plt.title(f"Class {np.argmax(labels[i])}")  # Shows the class index
    plt.axis('off')

plt.suptitle("Augmented Images from train_generator", fontsize=16)
plt.tight_layout()
plt.show()

print(images.dtype)
print(np.min(images), np.max(images))

"""## Modeling"""

import tensorflow as tf
from tensorflow.keras.applications import MobileNet
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

from sklearn.utils.class_weight import compute_class_weight
import numpy as np

# Assuming y_train contains one-hot encoded labels

# Convert one-hot encoded y_train back to class indices
y_train_indices = np.argmax(y_train, axis=1)

# Compute class weights using scikit-learn
class_weights = compute_class_weight(
    class_weight='balanced',              # Balances weights inversely proportional to class frequency
    classes=np.unique(y_train_indices),   # Unique class labels from the indices
    y=y_train_indices                     # Pass the class indices
)

# Convert to dictionary format required by model.fit
class_weights_dict = dict(enumerate(class_weights))

# Print for verification
print("Class weights:", class_weights_dict)

# Number of target classes
num_classes = 31

# Load MobileNet base model without the top classification layers
base_model = MobileNet(
    weights='imagenet',           # Use pre-trained weights from ImageNet
    include_top=False,
    input_shape=(224, 224, 3)
)

# Freeze all layers in the base model
for layer in base_model.layers:
    layer.trainable = False

# Add custom classification layers
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
x = Dense(256, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
output = Dense(num_classes, activation='softmax')(x)

# Build the final model
model = Model(inputs=base_model.input, outputs=output)

# Compile the model
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',  # Use sparse_categorical_crossentropy if labels are integers
    metrics=['accuracy']
)

# Print model summary
model.summary()

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

# Callbacks to save the best model and apply early stopping
checkpoint = ModelCheckpoint(
    'best_model.h5',           # File name to save best model
    monitor='val_loss',        # Monitor validation loss
    save_best_only=True,       # Save only when val_loss improves
    mode='min',                # Lower loss = better
    verbose=1
)

early_stop = EarlyStopping(
    monitor='val_loss',        # Monitor validation loss
    patience=3,                # Stop if no improvement after 3 epochs
    restore_best_weights=True, # Restore the best weights
    verbose=1
)

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=50,
    class_weight=class_weights_dict,
    callbacks=[checkpoint, early_stop]
)


# Save the entire model (architecture + weights + optimizer)
model.save("final_model.keras")
print(" Model saved successfully as: final_model.keras")

import matplotlib.pyplot as plt

# Plot training & validation accuracy values
plt.figure(figsize=(14, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy', color='green')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='blue')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.grid(True)

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss', color='red')
plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')
plt.grid(True)

plt.tight_layout()
plt.show()

"""## Fine-tuning"""

# Step 1: Unfreeze the last 30 layers of the base model
for layer in base_model.layers[-30:]:
    layer.trainable = True

# Step 2: Re-compile the model with a very small learning rate
from tensorflow.keras.optimizers import Adam
model.compile(
    optimizer=Adam(learning_rate=1e-5),  # Small LR to avoid large weight updates
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Step 3: Train the model again (fine-tuning) with class weights
fine_tune_history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=50,  # You can increase if training is stable
    class_weight=class_weights_dict,   # <-- هنا أضفت الـ class weights
    callbacks=[checkpoint, early_stop]
)

# Save the fine-tuned model in the new Keras format
model.save("final_finetuned_model.keras")
print(" Fine-tuned model saved as: final_finetuned_model.keras")

import matplotlib.pyplot as plt

def plot_training_comparison(history_base, history_finetune):
    # Combine accuracy
    acc = history_base.history['accuracy'] + history_finetune.history['accuracy']
    val_acc = history_base.history['val_accuracy'] + history_finetune.history['val_accuracy']

    # Combine loss
    loss = history_base.history['loss'] + history_finetune.history['loss']
    val_loss = history_base.history['val_loss'] + history_finetune.history['val_loss']

    epochs = range(1, len(acc) + 1)

    # Accuracy plot
    plt.figure(figsize=(14, 5))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, acc, label='Train Accuracy')
    plt.plot(epochs, val_acc, label='Validation Accuracy')
    plt.axvline(x=len(history_base.history['accuracy']), color='gray', linestyle='--', label='Fine-Tuning Start')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    # Loss plot
    plt.subplot(1, 2, 2)
    plt.plot(epochs, loss, label='Train Loss')
    plt.plot(epochs, val_loss, label='Validation Loss')
    plt.axvline(x=len(history_base.history['loss']), color='gray', linestyle='--', label='Fine-Tuning Start')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# Call the function
plot_training_comparison(history, fine_tune_history)

"""## Evaluation"""

from tensorflow import keras

# Load the model
model = keras.models.load_model('/content/final_finetuned_model.keras')

# Evaluate the model on the test data
loss, accuracy = model.evaluate(test_generator)
print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")

#Evaluate the model on test data
test_loss, test_accuracy = model.evaluate(test_generator)
print(f'Test Accuracy: {test_accuracy * 100:.2f}%')



"""## Testing"""

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# تأكد أن test_generator لا يخلط البيانات
test_generator = test_datagen.flow(X_test, y_test, batch_size=32, shuffle=False)

# Step 1: Predict class probabilities
y_pred_probs = model.predict(test_generator)

# Step 2: Convert predicted probabilities to class labels
y_pred = np.argmax(y_pred_probs, axis=1)

# Step 3: Convert one-hot encoded y_test to class labels
y_true = np.argmax(y_test, axis=1)

# Step 4: Classification report
print(classification_report(y_true, y_pred))

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Compute the confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Define class labels (you can replace with actual class names if available)
labels = sorted(set(y_true))

# Plot the confusion matrix using seaborn heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Make predictions on test data
y_pred = model.predict(test_generator)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

def plot_image(img_array, true_label, pred_label):
    plt.figure(figsize=(6, 6))
    if img_array.dtype == np.float32 or img_array.dtype == np.float64:
        img_array = img_array / 255.0  # تحويل القيم من [0, 255] إلى [0, 1]
    plt.imshow(img_array)
    plt.title(f"True Label: {true_label}\nPredicted Label: {pred_label}")
    plt.axis('off')
    plt.show()

# Plot a few test images with actual and predicted class names
num_images_to_plot = 5
for i in range(num_images_to_plot):
    # Get the image and its true label
    img = X_test[i]
    true_label = label_encoder.inverse_transform([y_true_classes[i]])[0]
    # Get the predicted label
    pred_label = label_encoder.inverse_transform([y_pred_classes[i]])[0]

    # Plot the image with title showing true and predicted labels
    plot_image(img, true_label, pred_label)

